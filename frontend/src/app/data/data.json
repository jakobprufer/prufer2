{
    "portfolio": [
        {
            "index": 0,
            "type": "info",
            "colour": "dark",
            "name": "Intro",
            "href": "intro",
            "title": [
                {
                    "type": "text",
                    "text": "Hi I'm"
                },
                {
                    "type": "headshot",
                    "src": "/jakob3.jpg",
                    "alt": "Jakob Prüfer smiling",
                    "h": 1200,
                    "w": 1200
                },
                {
                    "type": "text",
                    "text": "Jakob Prüfer,\n product designer and researcher."
                },
                {
                    "type": "text2",
                    "text": "This is my portfolio."
                }
            ],
            "subtitles": [
                [
                    {
                        "type": "text",
                        "text": "I'm currently designer and co-founder at"
                    },
                    {
                        "type": "icon",
                        "src": "/lostboy-brighter.jpg",
                        "alt": "Lost Boy Icon"
                    },
                    {
                        "type": "text",
                        "text": "Lost Boy."
                    }
                ],
                [
                    {
                        "type": "text",
                        "text": "I studied Psychology (BSc) at the"
                    },
                    {
                        "type": "icon",
                        "src": "/lse.jpg",
                        "alt": "LSE Icon"
                    },
                    {
                        "type": "text",
                        "text": "London School of Economics and UX Design (MA) at the"
                    },
                    {
                        "type": "icon",
                        "src": "/ual.jpg",
                        "alt": "UAL Icon"
                    },
                    {
                        "type": "text",
                        "text": "University of the Arts London."
                    }
                ],
                [
                    {
                        "type": "text",
                        "text": "I'm fluent in English, German, HTML, CSS, JavaScript,"
                    },
                    {
                        "type": "icon",
                        "src": "/react.svg",
                        "alt": "React Icon"
                    },
                    {
                        "type": "text",
                        "text": "React and"
                    },
                    {
                        "type": "icon",
                        "src": "/next.svg",
                        "alt": "Next Icon"
                    },
                    {
                        "type": "text",
                        "text": "Next.js."
                    }
                ]
            ]
        },
        {
            "index": 1,
            "type": "project",
            "colour": "light",
            "name": "Glace",
            "href": "glace",
            "brand": [
              {
                "type": "icon",
                "src": "glace.svg",
                "alt": "Lost Boy Icon",
                "h": 200,
                "w": 200
            },
              {
                "type": "text",
                "text": "Glace"
              }
            ],
            "title": [
              {
                "type": "text",
                "text": "Making sustainable investing palpable with arctic ice impact visualisation"
              }
            ],
            "timeFrame": "August - November 2023",
            "myRole": "Data Research, UX Design, Web Development",
            "contributors": [
                {
                    "name": "Manfredi Montaretto Marullo:",
                    "role": "UI Design, 3D, Usability Testing"
                }
            ],
            "tools": [
                {
                    "name": "Midjourney"
                },
                {
                    "name": "Next.js"
                },
                {
                    "name": "Figma"
                },
                {
                    "name": "Adobe CC"
                },
                {
                    "name": "Notion"
                }
            ],
            "status": "App: Prototype, Pitch Website: Live",
            "teaser": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "We found that sustainable investing doesn't feel tangible at all for Generation Z. We designed a mobile application with an augmented reality Arctic ice sheet that dynamically represents the amount of ice saved through user's green investments."
                    }
                ]
            ],
            "teaserShort": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "A mobile app using AI-driven data and augmented reality to show users how much Arctic ice they help to preserve through green investments"
                    }
                ]
            ],
            "detail": [
                [
                    {
                        "type": "heading",
                        "text": "Challenge"
                    },
                    {
                        "type": "text",
                        "text": "Our research revealed a disconnect for Generation Z between concern about climate change and engagement with sustainable investing. Despite high levels of climate change concern and openness to innovative investment platforms, sustainable investing options often seem intangible and not credible to this cohort. For the final master's project at the University of the Arts London, Manfredi and I challenged ourselves to engage young investors to leverage their financial decisions for positive environmental impact."
                    }
                ],
                [
                    {
                        "type": "heading",
                        "text": "Solution"
                    },
                    {
                        "type": "text",
                        "text": "The Glace prototype features an augmented reality Arctic ice sheet that dynamically represents the amount of ice saved through reducing CO2 emissions. The reduction is achieved by investing in green funds and compared to the benchmark of a conventional MSCI ACWI Portfolio. Emission amounts are sourced from AI-driven data provider Clarity AI. The app includes a beginner-friendly, preference-based portfolio and emphasises personal impact in the wider community context."
                    }
                ]
            ],
            "content": [
                {
                    "type": "feature",
                    "featureId": "glacemodel"
                },
                {
                  "type": "h2",
                  "text": "Timeline"
              },
              {
                "type": "timeline",
                "file": "/glace/TimelineGlace.svg"
              },
                {
                    "type": "h2",
                    "text": "Process"
                },
                {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Research"
                      },
                      {
                        "type": "headHeading",
                        "text": "Understanding the financial landscape and Gen Z's perception of sustainable investing"
                      },
                      {
                        "type": "headImg",
                        "src": "/glace/cube.webp",
                        "alt": "Digital illustration of an ice cube on black background",
                        "h": 1387,
                        "w": 778
                      }
                    ],
                    "content": [
                      {
                        "type": "text",
                        "text": "We conducted research in three stages:"
                      },
                      {
                        "type": "ol",
                        "items": [
                          "**Desk research** on impact investing and our target audience",
                          "**Generative research** including interviews and a drawing workshop",
                          "**Competitor analysis** and data provider analysis"
                        ]
                      },
                      {
                        "type": "image",
                        "src": "/glace/roadmap.webp",
                        "alt": "The initial roadmap outline for the project",
                        "w": 1511,
                        "h": 1105
                      },
                      {
                        "type": "caption",
                        "text": "**Image:** The initial roadmap outline for the project"
                      },
                      {
                        "type": "h4",
                        "text": "Desk Research"
                      },
                      {
                        "type": "text",
                        "text": "As our target audience we chose Generation Z (born between 1995 and 2010), specifically those residing in European urban centres. We found this group is driven by a number of motives in their spending and investing."
                      },
                      {
                        "type": "ul",
                        "items": [
                          "**Focus on innovation:** a strong inclination towards spending on technological and design-based innovations",
                          "**Insistence on convenience:** reliance on convenience, seen in preferences for time-saving devices, easy-to-acquire retail channels, and products with simplified experiences",
                          "**Desire for security:** Economic challenges shape Generation Z's focus on security, leading to an interest in saving and conservative spending"
                        ]
                      },
                      {
                        "type": "text",
                        "text": "We also discovered that people who care about the environment had a propensity to be less interested in or even defensive towards traditional finance. We saw this as an opportunity to shift away from the perception of traditional finance. From financial research we learned that ESG (Environmental, Social, and Governance) ratings are widely viewed as arbitrary and unreliable. We noticed however the emergence of new alternative data suppliers for sustainability data. We furthermore evaluated at a number of asset classes and ultimately decided on impact funds as the investing vehicle."
                      },
                      {
                        "type": "h4",
                        "text": "Generative Research"
                      },
                      {
                        "type": "image",
                        "src": "/glace/interviews2.webp",
                        "alt": "Some of our interviewees",
                        "w": 2392,
                        "h": 1040
                      },
                      {
                        "type": "caption",
                        "text": "**Image:** Some of our interviewees"
                      },
                      {
                        "type": "text",
                        "text": "We created a comprehensive research plan detailing the questions we aimed to answer. Based on those questions, we decided on in-depth interviews and a workshop as choice of methodology. With advisory help of a senior UX researcher at travel platform eDreams we reviewed our research plan and updated our interview script according to his remarks."
                      },
                      {
                        "type": "image",
                        "src": "/glace/interviewstats.webp",
                        "alt": "Interview demographics",
                        "w": 2240,
                        "h": 1336
                      },
                      {
                        "type": "caption",
                        "text": "**Image:** Interview demographics"
                      },
                      {
                        "type": "text",
                        "text": "Ten individuals from five different nations were interviewed for 20 to 45 minutes. We used affinity mapping and thematic analysis to conceptualise the results."
                      },
                      {
                        "type": "image",
                        "src": "/glace/transcripts.webp",
                        "alt": "",
                        "w": 2000,
                        "h": 1125
                      },
                      {
                        "type": "image",
                        "src": "/glace/sticky.webp",
                        "alt": "",
                        "w": 2720,
                        "h": 2268
                      },
                      {
                        "type": "text",
                        "text": "Key findings included:"
                      },
                      {
                        "type": "ul",
                        "items": [
                          "Participants struggled to see their impact in the context of the larger picture",
                          "Impact investing was not on participants’ minds as much as every day eco-friendly behaviour",
                          "Key barriers to investing are perceived insufficient wealth and perceived overwhelming complexity",
                          "Generation Z highly value convenience in investing",
                          "There is a strong sense of guilt associated with climate change"
                        ]
                      },
                      {
                        "type": "text",
                        "text": "In order to gather people's associations with CO2 emissions, we held a drawing workshop. This was meant to assist us in coming up with concepts for the visualisation. We invited 12 individuals from 12 different countries—half from Asia and the other half from Europe— to sketch their first ideas for the following questions: If CO2 Emissions were an object, what would they be? What could be one consequence of reducing CO2 emissions?"
                      },
                      {
                        "type": "image",
                        "src": "/glace/drawing1.webp",
                        "alt": "Drawings for the prompt: If CO2 Emissions were an object, what would they be?",
                        "w": 1792,
                        "h": 1344
                      },
                      {
                        "type": "caption",
                        "text": "**Drawings for the prompt:** If CO2 Emissions were an object, what would they be?"
                      },
                      {
                        "type": "image",
                        "src": "/glace/drawing2.webp",
                        "alt": "Drawings for the prompt: What could be one consequence of reducing CO2 emissions?",
                        "w": 1792,
                        "h": 1344
                      },
                      {
                        "type": "caption",
                        "text": "**Drawings for the prompt:** What could be one consequence of reducing CO2 emissions?"
                      },
                      {
                        "type": "h4",
                        "text": "Competitor Analysis"
                      },
                      {
                        "type": "text",
                        "text": "We analysed a total of 20 sustainable-focussed finance platforms of various types, including Flitinvest, Tomorrow Bank, Moniflo, Wealthfront and CIRCA5000. While sustainability was stressed in their motivations, we discovered that the presentation and user experience were not tailored for a target user that was concerned about the environment but did not understand the financial jargon that might be a barrier to investing."
                      },
                      {
                        "type": "image",
                        "src": "/glace/competitor.webp",
                        "alt": "",
                        "w": 2126,
                        "h": 1146
                      },
                      {
                        "type": "text",
                        "text": "When we looked at data providers, we saw an industry that seeks to enhance the reliability and trustworthiness of sustainability ratings, with key players like Clarity AI, Refinitiv, Truevalue Labs, and ESG Book. Clarity AI stood out for its comprehensive data on funds and companies, alignment with UN Sustainable Development Goals and CO2 emissions tracking."
                      }
                    ]
                  },
                  {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Ideation"
                      },
                      {
                        "type": "headHeading",
                        "text": "Exploring data visualisation and automated portfolio creation"
                      },
                      {
                        "type": "headImg",
                        "src": "/glace/datavis.jpg",
                        "alt": "Data visualisation mood board",
                        "w": 1920,
                        "h": 1080
                      }
                    ],
                    "content": [
                      {
                        "type": "caption",
                        "text": "**Image**: Data visualisation mood board"
                      },
                      {
                        "type": "text",
                        "text": "Following conceptualisation of the research, we chose to focus on people who were already concerned about climate change but were not familiar with finance, since we deemed it difficult to engage typical investors who are primarily motivated by profit maximisation. This meant that we would lower the financial entry barrier and focus on a strong visual storytelling component with our impact visualisation."
                      },
                      {
                        "type": "image",
                        "src": "/glace/sketches.webp",
                        "alt": "Early sketches for data visualisation and automatic portfolio",
                        "w": 3094,
                        "h": 2166
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Early sketches for data visualisation and automatic portfolio"
                      },
                      {
                        "type": "text",
                        "text": "In order to minimise the entrance barrier, we choose to use an automated portfolio that is based on simple user preferences, akin to a robo-advisor. In terms of customizability, we disagreed in a few areas as we tried to strike the ideal balance between the sense of ownership that comes from having created our own portfolio and the confusion and anxiety that comes with too much complexity."
                      },
                      {
                        "type": "image",
                        "src": "/glace/ice.webp",
                        "alt": "",
                        "w": 1920,
                        "h": 1080
                      },
                      {
                        "type": "text",
                        "text": "To visualise impact, we used inspiration from the drawing workshop. Initially we considered showing the volume of reduced CO2 in balloons. A green investment of $5000 for instance could be equivalent to the reduction of 8300 balloons CO2 yearly. We pivoted to Arctic ice as visualisation after finding it elicited a more emotional reaction and was easier to comprehend for our test subjects. The fact that a transatlantic return flight decreases the expanse of September Arctic Sea ice by about 2-3 m2 per passenger was surprising to most."
                      },
                      {
                        "type": "image",
                        "src": "/glace/data.webp",
                        "alt": "The scientific paper enabling us to calculate Arctic ice melt from CO2 emissions provided by ClarityAI (in the background)",
                        "w": 1920,
                        "h": 1080
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: The scientific paper enabling us to calculate Arctic ice melt from CO2 emissions provided by ClarityAI (in the background)"
                      },
                      {
                        "type": "text",
                        "text": "I was glad to pull from earlier financial research to access preliminary data. Assuming that money left in users bank accounts would be invested conventionally, we could now calculate a CO2 reduction for every dollar moved to “Glace”. For this we used the findings from:"
                      },
                      {
                        "type": "ul",
                        "items": [
                          "**Notz, D., & Stroeve, J. (2016).** Observed Arctic sea-ice loss directly follows anthropogenic CO2 emission. Science, 354(6313), 747-750."
                        ]
                      }
                    ]
                  } ,
                  {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Prototyping & Testing"
                      },
                      {
                        "type": "headHeading",
                        "text": "Building and testing a platform prototype and AR visualisation"
                      },
                      {
                        "type": "headImg",
                        "src": "/glace/ar.webp",
                        "alt": "",
                        "w": 2000,
                        "h": 1125
                      }
                    ],
                    "content": [
                      {
                        "type": "text",
                        "text": "We developed flow diagrams to determine the initial information architecture in the app and started wireframing a three or four tab structure. The first screen would focus predominantly on impact instead of financial return. We anticipated a challenge in keeping users engaged with the impact and a potential sense of guilt if they consistently bypassed it to access performance data. We refined the structure with low fidelity prototypes in Figma, evaluating various methods of user customisation, impact visualisation and portfolio presentation. We experimented with mobile devices’ haptic feedback to improve the UX of portfolio interactions."
                      },
                      {
                        "type": "image",
                        "src": "/glace/glaceflow.jpg",
                        "alt": "",
                        "w": 1280,
                        "h": 1638
                      },
                      {
                        "type": "image",
                        "src": "/glace/wiretable.webp",
                        "alt": "",
                        "w": 1024,
                        "h": 683
                      },
                      {
                        "type": "image",
                        "src": "/glace/wire1.webp",
                        "alt": "",
                        "w": 2000,
                        "h": 1163
                      },
                      {
                        "type": "text",
                        "text": "In moderated testing with the low fidelity prototype, we found a disconnect between the user choices and the portfolio composition. We would have to find a way to clarify that the allocation of funds was based on the user choices. We determined that we would provide additional affordance cues to simplify interaction with the portfolio UI. Furthermore, it seemed that our initial dark colour scheme was not perceived as trustworthy for a financial product."
                      },
                      {
                        "type": "image",
                        "src": "/glace/marta.webp",
                        "alt": "Notes from low fidelity moderated user testing",
                        "w": 2042,
                        "h": 1474
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Notes from low fidelity moderated user testing"
                      },
                      {
                        "type": "text",
                        "text": "For the arctic ice visualisation we iterated through numerous versions of in-app and augmented reality presentation. Challenges included how to give a sense of scale in the internal visualisations and how to shift the focus from individual blame to an optimistic communal perspective. For the augmented reality visualisation Manfredi developed a variable-size 3d model that could be opened in Apple’s AR Quick Look as well as Android’s ARCore."
                      },
                      {
                        "type": "image",
                        "src": "/glace/oldice3.jpg",
                        "alt": "Version 1 of the augmented ice visualisation",
                        "w": 2000,
                        "h": 1333
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Version 1 of the augmented ice visualisation"
                      },
                      {
                        "type": "image",
                        "src": "/glace/mariele.webp",
                        "alt": "Mariele Neudecker, Stolen Sunsets, 1996 served as visual inspiration",
                        "w": 1242,
                        "h": 1011
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Mariele Neudecker, Stolen Sunsets, 1996 served as visual inspiration"
                      },
                      {
                        "type": "video",
                        "src": "/glace/ar.mp4"
                      },
                      {
                        "type": "caption",
                        "text": "**Video**: Exploring the AR model on campus"
                      },
                      {
                        "type": "image",
                        "src": "/glace/icevisit.webp",
                        "alt": "Iterations of the in-app ice visualisations",
                        "w": 1974,
                        "h": 1110
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Iterations of the in-app ice visualisations"
                      },
                      {
                        "type": "text",
                        "text": "Taking into account the findings from testing, our high fidelity prototype featured a dashboard-like home screen that served as an access point to impact visualisation, portfolio performance, settings and app referral. It furthermore included educational articles and deep-dives the most innovative companies included in the funds."
                      },
                      {
                        "type": "text",
                        "text": "Final testing, with participants completing tasks in the app while thinking out loud, gave us markers for further improvements. Based on those we clarified some of the options in the settings page and adapted the portfolio section to allow a better overview. We were happy to find that most parts of the app, including the important impact visualisation, were received well."
                      },
                        {
                            "type": "video",
                            "src": "/glace/walkthrough.mp4"
                          },
                      {
                        "type": "caption",
                        "text": "**Video**: Walkthrough of the final prototype"
                      },
                      {
                        "type": "image",
                        "src": "/glace/impact.webp",
                        "alt": "Individual and community impact visualisation",
                        "w": 1544,
                        "h": 1158
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Individual and community impact visualisation"
                      }
                    ]
                  },
                  {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Delivery"
                      },
                      {
                        "type": "headHeading",
                        "text": "Creating brand, website and exhibition materials"
                      },
                      {
                        "type": "headImg",
                        "src": "/glace/brand.webp",
                        "alt": "",
                        "w": 2104,
                        "h": 1183
                      }
                    ],
                    "content": [
                      {
                        "type": "text",
                        "text": "After multiple temporary names we settled on the name “Glace” for the platform. Leveraging our initial vibrant colour palette suited for young audiences, we expanded the visual identity with an app icon and style guide. A simplified representation of a rotating fan, literally used to cool an environment down, became our app icon. Using an AI image generator we created ominous, glowing blue ice visuals on dark backgrounds. A top-down image of ice bears helped us to add emotion to the rather technical portrayal of ice surface areas."
                      },
                      {
                        "type": "image",
                        "src": "/glace/colours.webp",
                        "alt": "Icon and colour exploration",
                        "w": 1736,
                        "h": 977
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Icon and colour exploration"
                      },
                      {
                        "type": "text",
                        "text": "To pitch the idea, I created a website with Next.js, TypeScript, HTML, Sass and Framer Motion ([glace.earth](https://glace.earth)). It features attention grabbing scroll-transitions and mockups of the final prototype. For most of the visual content we leveraged AI image generation and expansion tools."
                      },
                      {
                        "type": "video",
                        "src": "/glace/ExpoFinal.mp4"
                      },
                      {
                        "type": "text",
                        "text": "For graduate showcase exhibition at University of the Arts London I created a video teaser explaining the concept. Apart from the video projection, our exhibition stall featured QR codes to open 3 sizes of our augmented ice sheet. Those were equivalent to yearly CO2 savings from: Using a reusable shopping bag all year, Investing $5000 dollars with “Glace”, Adopting on a plant-based diet."
                      },
                      {
                        "type": "text",
                        "text": "We received great responses during the exhibition and had the chance to connect with entrepreneurs in the sustainability space, agency designers and potential users."
                      }
                    ]
                  }                                                     
              ],
            "hero": {
                "type": "image",
                "src": "/glacebg4.jpg",
                "alt": "Screenshot of Glace App",
                "h": 2404,
                "w": 1575
            },
            "action": "See more",
            "externalAction": [
                {
                    "href": "https://glace.earth/",
                    "text": "Visit the website"
                },
                {
                    "icon": "./notion.svg",
                    "href": "https://glace.earth/",
                    "text": "See documentation"
                }
        ],
            "model": "/glaceModel.gltf"
        },
        {
            "index": 2,
            "type": "project",
            "colour": "dark",
            "name": "lostboy.tv",
            "href": "lostboy",
            "brand": [
                {
                    "type": "icon",
                    "src": "/lostboy-brighter.jpg",
                    "alt": "Lost Boy Icon",
                    "h": 200,
                    "w": 200
                },
                {
                    "type": "text",
                    "text": "lostboy.tv"
                }
            ],
            "title": [
              {
                "type": "text",
                "text": "Increasing client acquisition by optimising agency website with heap map analysis"
              }
            ],
            "timeFrame": "Januar - September 2023",
            "myRole": "Conception, Branding, Web Development",
            "contributors": [
                {
                    "name": "Luca Antoniazzi:",
                    "role": "Creative Direction"
                },
                {
                  "name": "Roman Dahm:",
                  "role": "Deployment"
              }
            ],
            "tools": [
                {
                    "name": "Next.js"
                },
                {
                    "name": "Figma"
                },
                {
                    "name": "Sanity CMS"
                },
                {
                    "name": "Midjourney"
                }
            ],
            "status": "Live",
            "teaser": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "London-based music supervision house Lost Boy were in need of a new brand and website to showcase their portfolio and improve customer communication. Coupled with a branded email campaign, the website launch sparked collaboration with leading advertising agencies, including Iris Worldwide, Leo Burnett and MullenLowe."
                    }
                ]
            ],
            "teaserShort": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "New website and brand for London-based music supervision house Lost Boy"
                    }
                ]
            ],
            "detail": [
                [
                    {
                        "type": "heading",
                        "text": "Challenge"
                    },
                    {
                        "type": "text",
                        "text": "London-based music supervision house Lost Boy needed a new brand and website to better showcase their portfolio and improve customer communication. Their mission is to craft impactful sonic landscapes for top brands, so the site's aesthetic had to align."
                    }
                ],
                [
                    {
                        "type": "heading",
                        "text": "Solution"
                    },
                    {
                        "type": "text",
                        "text": "I created a logo and visual identity to match Lost Boy's positioning. Using React, JavaScript, HTML and Sass I built a website that highlights their placements in campaigns for global brands. The new brand and site sparked partnerships with leading creative agencies like Iris Worldwide, Leo Burnett and MullenLowe."
                    }
                ]
            ],
            "content": [
                {
                  "type": "feature",
                  "featureId": "lostboylogo"
                },
                {
                  "type": "h2",
                  "text": "Timeline"
                },
                {
                "type": "timeline",
                "file": "/lostboy/TimelineLostBoy.svg"
                },
                {
                    "type": "h2",
                    "text": "Process"
                },
                {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Concept"
                      },
                      {
                        "type": "headHeading",
                        "text": "Exploring brand and website strategy"
                      },
                      {
                        "type": "headImg",
                        "src": "/lostboy/competitor.jpg",
                        "alt": "",
                        "w": 2000,
                        "h": 1125
                      }
                    ],
                    "content": [
                      {
                        "type": "text",
                        "text": "To kick off the project, I conducted analysis on Lost Boy's competitors and potential partners. I analysed the websites and branding of other UK music supervision houses to identify what strategies seemed to be working well and where there were opportunities for differentiation. I found a predominant focus on screen-filling video, however, many audio-focussed sites featured UI that felt outdated and image material not optimised for the size it was scaled to."
                      },
                      {
                        "type": "text",
                        "text": "In parallel, I explored advertising and creative agencies known for bold, innovative creative work like /RGA and Leo Burnett. These sites aimed to captivate visitors with striking imagery, kinetic type, and layered visual textures. They showed that in the advertising world, websites themselves are a branding exercise - not just vessels for displaying content."
                      },
                      {
                        "type": "text",
                        "text": "My analysis revealed clear objectives for the Lost Boy site. We needed to:"
                      },
                      {
                        "type": "ol",
                        "items": [
                          "Stand out immediately and look different from typical music supervision sites",
                          "Convey creativity and emotion like high-end advertising firms",
                          "Maintain minimal, sophisticated design while inviting visitors to interact and explore"
                        ]
                      }
                    ]
                  },
                  {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Ideation"
                      },
                      {
                        "type": "headHeading",
                        "text": "Iterating through prototypes with client input"
                      },
                      {
                        "type": "headImg",
                        "src": "/lostboy/ideation.jpg",
                        "alt": "",
                        "w": 2000,
                        "h": 1125
                      }
                    ],
                    "content": [
                      {
                        "type": "text",
                        "text": "With research complete, I moved into conceptualising visual and interaction design approaches for the site. I started by mapping out page structure and content hierarchy, keeping the layout clean and open with large, bold elements to achieve maximum visual impact."
                      },
                      {
                        "type": "text",
                        "text": "A key branding concept was finding a way to transition the logo from a stacked two-word layout to an inline single-word layout between home and Navigation Bar. I explored ideas around splitting and morphing the logo to accomplish this fluidly. I envisioned a moving starry background that creates a vivid, cinematic mood suited to engaging advertising creatives driven by emotion at the core of their work. We also shifted font selection from clean sans-serifs to elegant serif typefaces that feel classy and prestigious."
                      },
                      {
                        "type": "text",
                        "text": "For content types, I originally conceived presenting tracks sorted by genre with multiple audio players per page over backdrop videos or images that changed depending on the played track. However, through discussions with the creative director Luca Antoniazzi, we determined this overly busy direction could dilute the cinematic effect we wanted. Instead, we landed on a simplified video-focused layout with classic media players and audio samples underneath."
                      }
                    ]
                  },
                  {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Development"
                      },
                      {
                        "type": "headHeading",
                        "text": "Developing with Next.js, deploying on Kubernetes"
                      },
                      {
                        "type": "headImg",
                        "src": "/lostboy/development.jpg",
                        "alt": "",
                        "w": 1908,
                        "h": 1073
                      }
                    ],
                    "content": [
                      {
                        "type": "text",
                        "text": "With creative direction set, I developed the site using React, implementing React Router for page transitions and overlay effects on videos for visual interest. The site is fully responsive: on mobile small-screen devices, the navigation is accessed through an animated burger menu."
                      },
                      {
                        "type": "text",
                        "text": "To invite user interaction, I coded a custom dot cursor that expands when hovered over clickable elements. Applying a difference blend mode filter creates an interesting effect over vibrant colours and sharp edges, an effect also found on the navigation bar over scrolled elements. Another example of inviting interaction is giving the video thumbnails a slight zoom-in on hover."
                      },
                      {
                        "type": "text",
                        "text": "As requested, some projects can be expanded into full case studies on their respective paths. To demonstrate the iterative process of Lost Boy’s composition, I built custom audio players with live-updating progress indicators and interconnected play/pause functionality between the tracks."
                      },
                      {
                        "type": "text",
                        "text": "The end result is a website that realises the key objectives identified in research - an emotive, cinematic environment with bold branding and sophisticated interactivity tailored to the advertising world."
                      }
                    ]
                  }                                                                      
            ],
            "hero": {
                "type": "image",
                "src": "/lostboybg.png",
                "alt": "Screenshot of Lost Boy Website",
                "h": 2404,
                "w": 1575
            },
            "action": "See more",
            "externalAction": [
                {
                    "href": "https://lostboy.tv/",
                    "text": "Visit the website"
                }
        ]
        },
        {
            "index": 3,
            "type": "project",
            "colour": "light",
            "name": "CardioGuard",
            "href": "cardioguard",
            "brand": [
                {
                    "type": "icon",
                    "src": "/cardioguard.gif",
                    "alt": "CardioGuard Icon",
                    "h": 200,
                    "w": 200
                },
                {
                    "type": "text",
                    "text": "CardioGuard"
                }
            ],
            "title": [
              {
                "type": "text",
                "text": "Improving task completion rate in heart health app through guided testing with elderly users"
              }
            ],
            "subtitles": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "Health tracking can be stress-inducing and overwhelming. We designed a monitoring app for heart health and early signs of heart failure that feels friendly, science-backed and is accessible for elderly users."
                    }
                ],
                [
                    {
                        "type": "heading",
                        "text": "My Role"
                    },
                    {
                        "type": "text",
                        "text": "User Testing, UI Design"
                    }
                ]
            ],
            "timeFrame": "February 2023",
            "myRole": "User Testing, UI Design",
            "contributors": [
                {
                    "name": "Manfredi Montaretto Marullo"
                }
            ],
            "status": "Prototype",
            "teaser": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "A hearth health tracking app friendly, science-backed and is accessible for elderly users"
                    }
                ]
            ],
            "teaserShort": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "Hearth health tracking app that feels friendly, science-backed and was tested for accessibility with elderly users"
                    }
                ]
            ],
            "detail": [
                [
                    {
                        "type": "heading",
                        "text": "Challenge"
                    },
                    {
                        "type": "text",
                        "text": "Health tracking can be stress-inducing and overwhelming. Particularly for elderly users there is a gap between usefulness and usability of digital applications."
                    }
                ],
                [
                    {
                        "type": "heading",
                        "text": "Solution"
                    },
                    {
                        "type": "text",
                        "text": "We designed a monitoring app for heart health and early signs of heart failure that feels friendly, science-backed and is accessible for elderly users."
                    }
                ]
            ],
            "content": [
              {
                "type": "h2",
                "text": "Timeline"
              },
              {
                "type": "timeline",
                "file": "/cardioguard/TimelineCardioGuard.svg"
              },
              {
                "type": "h2",
                "text": "Process"
              },
              {
                "type": "expandable",
                "head": [
                  {
                    "type": "phase",
                    "text": "Phase 1"
                  },
                  {
                    "type": "headHeading",
                    "text": "Research"
                  },
                  {
                    "type": "headImg",
                    "src": "/cardioguard/musigk.jpg",
                    "alt": "Charité Researcher Nicolas Musigk",
                    "w": 817,
                    "h": 460
                  }
                ],
                "content": [
                  {
                    "type": "caption",
                    "text": "**Image**: Charité Researcher Nicolas Musigk"
                  },
                  {
                    "type": "text",
                    "text": "We begun research with a semi-structured interview with a cardiology researcher at Charité in Berlin, who’s MD thesis looks at early detection of cardiovascular disease. I got a good overview over what patient data and symptoms would be helpful to collect and determined some pain points for doctors and patients in the diagnostic progress."
                  },
                  {
                    "type": "text",
                    "text": "Research into the current scientific literature confirmed our concept in showing that AI is increasingly making accurate inferences about heart performance from ECG readings alone when other methods of examination would have been necessary in the past. Probing into the behavioural side of health applications, we determined it would be better to keep detailed measurements “under the hood” and only show a general status, as a lay person is often not qualified to judge if abnormal values are just unique traits or pathologic irregularities. We found that to keep engagement with the app as high as possible, simplification of complex data would be effective both for people high and low in health literacy."
                  },
                  {
                    "type": "image",
                    "src": "/cardioguard/competitors.jpg",
                    "alt": "",
                    "w": 1920,
                    "h": 1080
                  },
                  {
                    "type": "text",
                    "text": "In a competitor analysis we found that third party apps often did not seem very trustworthy both in method of measurement as well as in presentation and design. Another issue we found with apps like Apple’s “Health” was they presented users with too many values and health aspects so they lost transparency and clarity in UX."
                  },
                  {
                    "type": "text",
                    "text": "Our overall research takeaway remained: Health tracking and health-related content on the internet can be intimidating and overburdening. Ironically, stress and anxiety have adverse effects on cardiac health. Therefore the app should display only actionable information in a manner that is not anxiety-inducing where it doesn’t need to be."
                  }
                ]
              },
              {
                "type": "expandable",
                "head": [
                  {
                    "type": "phase",
                    "text": "Phase 2"
                  },
                  {
                    "type": "headHeading",
                    "text": "Definition"
                  },
                  {
                    "type": "headImg",
                    "src": "/cardioguard/concept.jpg",
                    "alt": "",
                    "w": 1920,
                    "h": 1080
                  }
                ],
                "content": [
                  {
                    "type": "text",
                    "text": "Structuring our research, we then organised data that could be measured, data we needed users to report, personal data needed on sign up and aspects of presentation in an affinity diagram. We concluded that our main focuses for the project were:"
                  },
                  {
                    "type": "ul",
                    "items": [
                      "Creating a human and personal touch",
                      "Make it easy to understand and read",
                      "Non-frightening presentation and no rushed diagnosis",
                      "Reminding patients to keep information up to date"
                    ]
                  },
                  {
                    "type": "text",
                    "text": "Accordingly, we created personas to further understand users needs and behaviours, such as:"
                  },
                  {
                    "type": "text",
                    "text": "Mary, 69 years old. Mary is a retired teacher who enjoys gardening and doing yoga. She is concerned about her heart health and wants to monitor her condition regularly, which is why her GP has recommended CardioGuard to her. She has some experience using smartphones but doesn't want to spend too much time figuring out how to use the app. Mary wants the app to be easy to use and understand, and wants to receive alerts if any issues are detected. She gets frustrated when technology is overly complicated or difficult to use."
                  }
                ]
              },
              {
                "type": "expandable",
                "head": [
                  {
                    "type": "phase",
                    "text": "Phase 3"
                  },
                  {
                    "type": "headHeading",
                    "text": "Ideation"
                  },
                  {
                    "type": "headImg",
                    "src": "/cardioguard/ideation3.jpg",
                    "alt": "",
                    "w": 1920,
                    "h": 1080
                  }
                ],
                "content": [
                  {
                    "type": "text",
                    "text": "In the ideation stage, I was able to learn a lot from Manfredi who came into the project with a few years of professional design experience. Together we created flow charts to structure the applications functions and to lay out processes like the sign up. We started with hand sketches to get a feel for available space and basic placement, then went on to create digital wireframes."
                  },
                  {
                    "type": "image",
                    "src": "/cardioguard/flows.jpg",
                    "alt": "",
                    "w": 1920,
                    "h": 1080
                  },
                  {
                    "type": "image",
                    "src": "/cardioguard/ideation2.jpg",
                    "alt": "",
                    "w": 1920,
                    "h": 1080
                  },
                  {
                    "type": "text",
                    "text": "We decided we would not use the colour red or alarming language; the main status would only be regular or irregular. For a patient with known issues, the status would still remain regular as long as no changes in condition were detected. We also added an animated doctor mannequin to make the app friendly and provide a character to the name “CardioGuard”."
                  }
                ]
              },
              {
                "type": "expandable",
                "head": [
                  {
                    "type": "phase",
                    "text": "Phase 4"
                  },
                  {
                    "type": "headHeading",
                    "text": "User Testing"
                  },
                  {
                    "type": "headImg",
                    "src": "/cardioguard/testing.webp",
                    "alt": "",
                    "w": 1920,
                    "h": 1080
                  }
                ],
                "content": [
                  {
                    "type": "text",
                    "text": "We tested our Figma prototype with eight users of ages between 54 and 86. This phase for me served as a reminder about how important it is to challenge own assumptions – what might be true and obvious for you might not be the case for every user."
                  },
                  {
                    "type": "image",
                    "src": "/cardioguard/corrections.jpg",
                    "alt": "",
                    "w": 1920,
                    "h": 1080
                  },
                  {
                    "type": "text",
                    "text": "For instance, we had put the option to share a report in a three-dot sub menu. When asked to find the function, most of our test subjects did not understand what the three dots meant. Where for our generation it might have been clear that they indicated the presence of “more options”, for someone with lower digital literacy they remained obscure. We therefore decided to make all important functions immediately visible and label icons that might be unclear. We also re-introduced a bottom tab bar to make functions easier to find."
                  }
                ]
              },
              {
                "type": "expandable",
                "head": [
                  {
                    "type": "phase",
                    "text": "Phase 5"
                  },
                  {
                    "type": "headHeading",
                    "text": "Final Prototype"
                  },
                  {
                    "type": "headImg",
                    "src": "/cardioguard/final1.jpg",
                    "alt": "",
                    "w": 1920,
                    "h": 1080
                  }
                ],
                "content": [
                  {
                    "type": "text",
                    "text": "After the two-week project we arrived at our current prototype. Here are some impressions including the Figma design system we created in the process."
                  },
                  {
                    "type": "image",
                    "src": "/cardioguard/final2.jpg",
                    "alt": "",
                    "w": 1730,
                    "h": 1730
                  }
                ]
              },                  
              {
                "type": "ul",
                "items": [
                  "Reminder to challenge my own assumptions – what might be true and obvious for you might not be the same for every user",
                  "Improving my design abilities and consideration for accessibility and text size adaptability",
                  "Highlighting the importance of solid project documentation in teams"
                ]
              }
            ],
            "hero": {
                "type": "image",
                "src": "/cardioguardbg5.jpg",
                "alt": "CardioGuard app screen and Photo of user testing",
                "h": 3000,
                "w": 2000
            },
            "action": "See more"
        },
        {
            "index": 4,
            "type": "project",
            "colour": "dark",
            "name": "Birdsong",
            "href": "birdsong",
            "brand": [
                {
                    "type": "text",
                    "text": "Urban Birdsong"
                }
            ],
            "title": [
              {
                "type": "text",
                "text": "Highlighting the impact of urban light pollution on birdsong in interactive sound installation"
              }
            ],
            "timeFrame": "10-24/11/2022",
            "myRole": "Perceptional Research, Interactive Technology",
            "contributors": [
                {
                    "name": "Carlotta Montanari"
                },
                {
                    "name": "Lingjia Fang"
                },
                {
                    "name": "Rebecca Hodge"
                },
                {
                    "name": "Roshni Suri"
                }
            ],
            "tools": [
                {
                    "name": "Arduino"
                },
                {
                    "name": "Ableton Live"
                }
            ],
            "status": "Exhibited 2022",
            "teaser": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "We researched and developed an interactive sound installation that highlights the impact of urban light pollution on the sleep patterns and health of birds."
                    }
                ]
            ],
            "teaserShort": [
                [
                    {
                        "type": "heading",
                        "text": "About"
                    },
                    {
                        "type": "text",
                        "text": "An interactive, light-responsive sound installation highlighting the impact of urban light pollution on birds' sleep patterns"
                    }
                ]
            ],
            "detail": [
                [
                    {
                        "type": "heading",
                        "text": "Brief"
                    },
                    {
                        "type": "text",
                        "text": "We very much understand the world visually, especially when it comes to design. We use the word imagination, derived from the “image”, even when what we imagine are sounds. All the more inviting was the challenge to design around sound, specifically birdsong in an urban environment. Unlike most animals, birds use identical sounds in patterns like we do with our human phonology - even though the sounds don’t seem to carry the same depth of meaning. Birdsong has served as inspiration for various classical composers and can contribute to improved mood and mental health – which I can affirm from personal experience, excluding the sunrise - announcing birdsong that haunts me when I try to fall asleep after a night of dancing."
                    }
                ],
                [
                    {
                        "type": "heading",
                        "text": "Outcome"
                    },
                    {
                        "type": "text",
                        "text": "We developed an interactive sound installation that highlights the impact of urban light pollution on the sleep patterns and health of birds. It was exhibited as part of the 'Studio Practices' module at the University of the Arts London."
                    }
                ]
            ],
            "content": [
                {
                  "type": "h2",
                  "text": "Timeline"
                },
                {
                  "type": "timeline",
                  "file": "/birdsong/TimelineBirdsong.svg"
                },
                {
                    "type": "h2",
                    "text": "Process"
                },
                {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Phase 1"
                      },
                    {
                            "type": "headHeading",
                            "text": "Soundwalks"
                        },
                      {
                        "type": "headImg",
                        "src": "/birdsong/klee.jpg",
                        "alt": "",
                        "w": 1720,
                        "h": 967
                      }
                    ],
                    "content": [
                        {
                            "type": "caption",
                            "text": "**Image**: Paul Klee, Vogelgarten, 1924"
                        },
                      {
                        "type": "text",
                        "text": "We commenced research using the soundwalking methodology, which uses a walk as a tool for active focus on the sonic environment. We decided to conduct soundwalking research separately, each in different areas of London, including central Knightsbridge and South Bank as well as leafy Sydenham. I did mine in Forest Hill and Catford at around 5pm in early winter darkness. The air had a stale quality, lacking altogether the freshness of an evening breeze, and a muffling mist had settled over the hills, blurring the distant skyscrapers, and damping the soundscape. Only twice I heard birds, in two different parks I crossed, but calling from an indiscernible location and quieting as I tried to walk towards the source. Both times it seemed to be the same species, screeching in a short high-pitched tone. I heard various birds of the mechanical kind – with planes crossing over towards Heathrow in intervals of less than 30 seconds - as well as distant police sirens and dog barking, cars, trains, people talking and laughing. My favourite moment was standing in a tucked-away, pitch-black meadow in Ladywell Fields - with all this London soundscape still audible but at the same time hidden away from sight."
                      },
                      {
                        "type": "image",
                        "src": "/birdsong/routes.jpg",
                        "alt": "Soundwalk Routes",
                        "w": 1123,
                        "h": 881
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Soundwalk Routes"
                      }
                    ]
                  },
                  {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Phase 2"
                      },
                      {
                        "type": "headHeading",
                        "text": "Physical Mapping"
                      },
                      {
                        "type": "headImg",
                        "src": "/birdsong/mapping.jpg",
                        "alt": "",
                        "w": 1698,
                        "h": 955
                      }
                    ],
                    "content": [
                      {
                        "type": "text",
                        "text": "From our collective recordings and notes of the soundwalks we identified common themes. An observation that stood out to all of us were the many layers of sound, most of them urban noises. The birdsong was routinely hidden beneath them, only noticed when listening intentionally. From this notion came our first prototype: a sound “sandwich”, made from layers of different materials representing natural and urban sounds. To further develop this idea of representing sound in a physical form, we then listened to the recordings individually and drew on paper what came to our head. Curiously, our sketches were very similar for individual bird species. We used sharp quick lines for screechy sounds and dainty, squiggly lines for melodic singsong. Most of us used notation in lines from left to right reminiscent of traditional musical notation. Following advice from our tutorial, we tried to bring these shapes into 3D form using materials such as toothpicks, fabric, wire and paper. We presented a mapped model of the soundwalks, placing birdsong representations within the cityscape."
                      },
                      {
                        "type": "image",
                        "src": "/birdsong/mapping2.jpg",
                        "alt": "",
                        "w": 1698,
                        "h": 1192
                      }
                    ]
                  },
                  {
                    "type": "expandable",
                    "head": [
                      {
                        "type": "phase",
                        "text": "Phase 3"
                      },
                      {
                        "type": "headHeading",
                        "text": "Birdnest Installation"
                      },
                      {
                        "type": "headImg",
                        "src": "/birdsong/nest.jpg",
                        "alt": "",
                        "w": 2000,
                        "h": 1124
                      }
                    ],
                    "content": [
                      {
                        "type": "text",
                        "text": "To find a more unique approach then, we thought about the relationship of birdsong and time of day, as we mostly associated birdsong with sunrise and sunset times. Following further literature review, we then decided to focus on birdsong in connection to urban light pollution. Birds rely on light as cue for their activity and singing patterns. Artificial light at night makes birds sing earlier both in dusk and dawn than they would naturally. It negatively affects their melatonin levels, leading to irregularities in their inner body clock and disrupted sleep. Other negative effects of artificial light include disorientation of migrating birds, worsened stress response and impaired immune function. These findings added a new purpose that we could incorporate in the design if we were able to raise awareness for the issue."
                      },
                      {
                        "type": "image",
                        "src": "/birdsong/construction.jpg",
                        "alt": "",
                        "w": 1667,
                        "h": 815
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: Construction of the nest. The sensor was later covered by twigs and leaves"
                      },
                      {
                        "type": "text",
                        "text": "We connected with the Creative Technology Lab on campus and borrowed a light sensor with the Arduino microcontroller board to trigger an output. Combining good elements from previous ideas, we settled on the concept of an augmented bird nest that would play sounds based on light shun on it. We built the nest using twigs from a neighbouring park and reinforced it with wire. We then placed the sensor and microcontroller in the middle of the nest covered by more twigs; via a USB cable, we could now trigger any parameter in the digital audio workstation Ableton Live. At different levels of light, low pass filters would open to make more and more birds audible - climaxing in a full choir of reverbed birdsong and loud screeching. The light sensor also controlled a white noise synthesizer, making the pitch higher with more light and adding a slightly threatening tone to the installation."
                      },
                      {
                        "type": "image",
                        "src": "/birdsong/shadow.jpg",
                        "alt": "The installation added light and shadow as a second element to the sound",
                        "w": 2000,
                        "h": 1334
                      },
                      {
                        "type": "caption",
                        "text": "**Image**: The installation added light and shadow as a second element to the sound"
                      },
                      {
                        "type": "text",
                        "text": "We dimmed the room for presentation, setting the scene for the nest in a in a city night-time setting. Participants were given a flashlight and instructed to examine the nest. The experience of surprise and interactivity with the light-reactive sound worked very well."
                      }
                    ]
                  }                                    
            ],
            "hero": {
                "type": "video",
                "src": "/birdsong.mp4",
                "alt": "Two people interacting with the Urban Birdsong installation in a dark studio",
                "thumbnail": "/birdsong5.jpg"
            },
            "action": "See more"
        },
        {
            "index": 5,
            "type": "info",
            "colour": "light",
            "name": "Outro",
            "href": "outro",
            "preTitle": [
              {
                "type": "text",
                "text": "Get in touch:"
              }
            ],
            "title": [
                {
                    "type": "link",
                    "text": "jakob@prufer.co",
                    "href": "mailto:jakob@prufer.co"
                }
            ]
        }
    ]
}
